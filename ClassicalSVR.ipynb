{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# 1) Load QM7, Flatten 23x23 Coulomb Matrices => 529 features\n",
    "\n",
    "\n",
    "def load_qm7_coulomb_flat(matfile='qm7.mat'):\n",
    "    \"\"\"\n",
    "    Loads the QM7 dataset from `matfile`.\n",
    "    For each 23x23 Coulomb matrix, flattens into 529 features.\n",
    "    Returns:\n",
    "      X_flat: (N, 529) array of flattened Coulomb matrices\n",
    "      Y:      (N,) array of target energies\n",
    "    \"\"\"\n",
    "    data = scipy.io.loadmat(matfile)\n",
    "    C_matrices = data['X']  # shape: (N, 23, 23)\n",
    "    energies   = data['T'].ravel()  # shape: (N,)\n",
    "\n",
    "    N = C_matrices.shape[0]\n",
    "    X_list = []\n",
    "    for i in range(N):\n",
    "        # Flatten 23x23 => 529 features\n",
    "        M_flat = C_matrices[i].flatten()\n",
    "        X_list.append(M_flat)\n",
    "    X_flat = np.array(X_list)  # shape (N, 529)\n",
    "    return X_flat, energies\n",
    "\n",
    "\n",
    "# 2) Classical SVR with Feature + Target Scaling\n",
    "\n",
    "\n",
    "def main_classical_svr_scaled_coulomb_matrix_demo(\n",
    "    matfile='qm7.mat',\n",
    "    subset_size=500,\n",
    "    test_size=0.2,\n",
    "    random_seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Loads dataset, flattens each 23x23 => 529 features\n",
    "    2) Subsamples\n",
    "    3) Scales features with StandardScaler\n",
    "    4) Scales targets (subtract mean, divide std)\n",
    "    5) Train/test split\n",
    "    6) Fits a classical SVR (RBF)\n",
    "    7) Inverts target transform, measures final MAE, R^2\n",
    "    \"\"\"\n",
    "    # 1) Load data\n",
    "    X_all, Y_all = load_qm7_coulomb_flat(matfile)\n",
    "    Ntotal = len(X_all)\n",
    "    print(f\"Loaded {Ntotal} molecules with flattened 23x23 => 529 features.\")\n",
    "\n",
    "    # 1b) (Optional) Load 23-dimensional eigenvalues instead\n",
    "    # Uncomment the section below to switch to eigenvalue features\n",
    "    # from your eigenvalue loader:\n",
    "   \"\"\"\n",
    "    print(\"Computing 23 eigenvalues for each matrix…\")\n",
    "    X_eig = []\n",
    "    for M_flat in X_all:\n",
    "        M = M_flat.reshape(23, 23)              # back to 23x23\n",
    "        M = 0.5 * (M + M.T)                     # symmetrize\n",
    "        e_vals = np.linalg.eigvalsh(M)          # sorted by default\n",
    "        X_eig.append(e_vals)\n",
    "    X_all = np.array(X_eig)                    # shape (Ntotal, 23)\n",
    "    print(f\"Converted to 23-dimensional eigenvalue features.\")\n",
    "   \"\"\"\n",
    "\n",
    "    # 2) Subsample\n",
    "    np.random.seed(random_seed)\n",
    "    idxs = np.random.choice(Ntotal, size=subset_size, replace=False)\n",
    "    X_sub = X_all[idxs]\n",
    "    Y_sub = Y_all[idxs]\n",
    "\n",
    "    # 3) Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_sub_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "    # 4) Scale targets\n",
    "    Y_mean = np.mean(Y_sub)\n",
    "    Y_std  = np.std(Y_sub)\n",
    "    Y_sub_scaled = (Y_sub - Y_mean)/Y_std\n",
    "\n",
    "    # 5) Train/test split\n",
    "    X_train_scaled, X_test_scaled, Y_train_scaled, Y_test_scaled = train_test_split(\n",
    "        X_sub_scaled, Y_sub_scaled,\n",
    "        test_size=test_size,\n",
    "        random_state=random_seed\n",
    "    )\n",
    "    print(f\"Train size={X_train_scaled.shape[0]}, Test size={X_test_scaled.shape[0]}\")\n",
    "\n",
    "    # 6) Fit classical SVR with RBF kernel\n",
    "    svr = SVR(kernel='rbf', C=1e4, gamma=1e-3, epsilon=0.01)\n",
    "    svr.fit(X_train_scaled, Y_train_scaled)\n",
    "\n",
    "    # Predict (in scaled space)\n",
    "    Y_pred_scaled = svr.predict(X_test_scaled)\n",
    "\n",
    "    # 7) Invert target transform\n",
    "    Y_pred = Y_pred_scaled * Y_std + Y_mean\n",
    "    Y_test = Y_test_scaled * Y_std + Y_mean\n",
    "\n",
    "    # Evaluate\n",
    "    mae = mean_absolute_error(Y_test, Y_pred)\n",
    "    r2  = r2_score(Y_test, Y_pred)\n",
    "\n",
    "    print(\"\\nClassical SVR (RBF) on 529D Coulomb + Scaled Features/Targets:\")\n",
    "    print(f\"  Subset size: {subset_size}\")\n",
    "    print(f\"  MAE = {mae:.3f}\")\n",
    "    print(f\"  R^2 = {r2:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    main_classical_svr_scaled_coulomb_matrix_demo(\n",
    "        matfile='qm7.mat',\n",
    "        subset_size=7165,\n",
    "        test_size=0.2,\n",
    "        random_seed=42\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINDS THE BEST 300 QUANTUM SUPPORT VECTORS AND RANKS THEM\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#Loaders \n",
    "def load_flat(matfile='qm7.mat'):\n",
    "    data = scipy.io.loadmat(matfile)\n",
    "    C = data['X']         # shape (N,23,23)\n",
    "    Y = data['T'].ravel()\n",
    "    X_flat = np.stack([M.flatten() for M in C], axis=0)\n",
    "    return X_flat, Y\n",
    "\n",
    "def load_eig(matfile='qm7.mat'):\n",
    "    data = scipy.io.loadmat(matfile)\n",
    "    C = data['X']\n",
    "    Y = data['T'].ravel()\n",
    "    eigs = []\n",
    "    for M in C:\n",
    "        M_sym = 0.5*(M + M.T)\n",
    "        e = np.linalg.eigvalsh(M_sym)\n",
    "        eigs.append(np.sort(e))\n",
    "    return np.array(eigs), Y\n",
    "\n",
    "\n",
    "#SVR + Support‐Vector Inspection\n",
    "def inspect_svr_support(loader, feature_name, subset_size=500, test_size=0.2, random_seed=42):\n",
    "    \"\"\"\n",
    "    Trains an SVR on a random subset of the provided features,\n",
    "    then prints the top-300 support vectors by |dual_coef_|.\n",
    "    \"\"\"\n",
    "    # 1) Load & subsample\n",
    "    X_all, Y_all = loader('qm7.mat')\n",
    "    np.random.seed(random_seed)\n",
    "    idxs = np.random.choice(len(X_all), size=subset_size, replace=False)\n",
    "    X_sub, Y_sub = X_all[idxs], Y_all[idxs]\n",
    "\n",
    "    # 2) Scale features & targets\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_sub)\n",
    "    Y_mean, Y_std = Y_sub.mean(), Y_sub.std()\n",
    "    Y_scaled = (Y_sub - Y_mean) / Y_std\n",
    "\n",
    "    # 3) Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, Y_scaled, test_size=test_size, random_state=random_seed\n",
    "    )\n",
    "\n",
    "    # 4) Fit SVR\n",
    "    svr = SVR(kernel='rbf', C=1e4, gamma=1e-3, epsilon=0.01)\n",
    "    svr.fit(X_train, y_train)\n",
    "\n",
    "    # 5) Inspect support vectors\n",
    "    sv_indices = svr.support_\n",
    "    alphas     = np.abs(svr.dual_coef_).ravel()\n",
    "    order      = np.argsort(-alphas)\n",
    "    top30_idx  = sv_indices[order[:300]]\n",
    "    top30_alph = alphas[order[:300]]\n",
    "\n",
    "    print(f\"\\n=== {feature_name} features ===\")\n",
    "    print(\"Top 300 support-vector indices (in the TRAIN set):\", top30_idx)\n",
    "    print(\"Their dual-coeff magnitudes:           \", top30_alph)\n",
    "\n",
    "    # 6) Final evaluation\n",
    "    y_pred_s = svr.predict(X_test)\n",
    "    y_pred   = y_pred_s * Y_std + Y_mean\n",
    "    y_true   = y_test * Y_std + Y_mean\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2  = r2_score(y_true, y_pred)\n",
    "    print(f\"MAE = {mae:.3f}   R² = {r2:.3f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Flat 529-D run\n",
    "    inspect_svr_support(load_flat, '529D')\n",
    "    # Eigenspectrum 23-D run\n",
    "    inspect_svr_support(load_eig,  '23D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# “best” support-vector indices for each representation\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "BEST_IDS_529 = [\n",
    "    193, 19, 94, 158, 370, 0, 148, 281, 218, 214,\n",
    "    52, 87, 186, 35, 337, 244, 267, 1, 342, 79,\n",
    "    232, 183, 364, 348, 139, 369, 64, 188, 338, 304,\n",
    "    128, 11, 172, 92, 393, 97, 149, 386, 350, 222,\n",
    "    398, 181, 213, 164, 41, 143, 67, 271, 210, 202,\n",
    "    275, 372, 141, 258, 247, 105, 211, 23, 130, 166,\n",
    "    86, 124, 171, 132, 47, 208, 104, 243, 324, 399,\n",
    "    336, 159, 51, 365, 46, 305, 390, 257, 196, 119,\n",
    "    233, 12, 242, 274, 144, 106, 394, 215, 341, 366,\n",
    "    382, 251, 250, 288, 272, 317, 8, 209, 63, 137,\n",
    "    295, 111, 110, 53, 238, 54, 69, 253, 45, 109,\n",
    "    167, 206, 195, 173, 17, 343, 371, 216, 322, 40,\n",
    "    121, 308, 355, 312, 20, 198, 353, 294, 36, 321,\n",
    "    160, 204, 284, 282, 248, 161, 225, 234, 347, 15,\n",
    "    201, 279, 185, 140, 7, 96, 200, 177, 65, 133,\n",
    "    169, 254, 349, 120, 344, 117, 155, 95, 127, 175,\n",
    "    346, 71, 178, 33, 162, 77, 352, 392, 179, 88,\n",
    "    240, 184, 118, 345, 311, 81, 262, 91, 359, 306,\n",
    "    190, 291, 18, 276, 231, 326, 269, 24, 199, 31,\n",
    "    189, 146, 174, 135, 157, 145, 287, 325, 70, 389,\n",
    "    59, 300, 101, 285, 122, 277, 339, 21, 273, 358,\n",
    "    333, 100, 226, 180, 299, 237, 142, 297, 309, 80,\n",
    "    14, 10, 116, 5, 363, 203, 114, 72, 197, 212,\n",
    "    377, 256, 89, 223, 307, 289, 4, 50, 316, 43,\n",
    "    235, 27, 268, 42, 56, 129, 375, 255, 266, 246,\n",
    "    303, 22, 85, 385, 354, 82, 278, 368, 29, 138,\n",
    "    25, 361, 383, 207, 310, 236, 13, 150, 192, 290,\n",
    "    388, 75, 245, 315, 125, 263, 313, 397, 49, 351,\n",
    "    153, 239, 228, 296, 194, 379, 205, 230, 2, 298,\n",
    "    131, 113, 261, 314, 32, 384, 252, 37, 98, 84\n",
    "]\n",
    "\n",
    "BEST_IDS_23 = [\n",
    "    305, 286, 145, 285, 284, 148, 281, 280, 279, 152,\n",
    "    143, 277, 276, 157, 158, 275, 161, 274, 273, 270,\n",
    "    166, 154, 269, 287, 139, 112, 309, 306, 115, 117,\n",
    "    121, 122, 301, 125, 140, 299, 297, 129, 130, 131,\n",
    "    292, 290, 135, 137, 138, 298, 268, 169, 263, 249,\n",
    "    204, 246, 206, 207, 245, 244, 243, 213, 202, 214,\n",
    "    241, 217, 239, 235, 221, 232, 231, 224, 230, 242,\n",
    "    251, 252, 198, 262, 173, 175, 176, 177, 178, 179,\n",
    "    180, 261, 260, 259, 185, 186, 187, 188, 189, 257,\n",
    "    193, 194, 196, 256, 111, 311, 227, 107, 38, 39,\n",
    "    40, 41, 361, 45, 48, 49, 366, 50, 52, 109,\n",
    "    54, 56, 354, 61, 352, 351, 51, 64, 368, 373,\n",
    "    397, 5, 6, 390, 9, 384, 383, 15, 29, 382,\n",
    "    379, 21, 377, 375, 374, 25, 26, 27, 18, 350,\n",
    "    53, 349, 85, 87, 88, 66, 91, 92, 93, 95,\n",
    "    96, 325, 321, 101, 103, 105, 106, 331, 83, 89,\n",
    "    334, 348, 345, 82, 70, 74, 344, 341, 71, 79,\n",
    "    336, 303, 102, 34, 132, 46, 191, 160, 389, 392,\n",
    "    86, 199, 391, 313, 182, 174, 155, 381, 209, 362,\n",
    "    304, 14, 386, 317, 31, 226, 367, 72, 358, 378,\n",
    "    219, 73, 0, 393, 104, 201, 267, 7, 237, 2,\n",
    "    387, 134, 114, 324, 37, 222, 81, 288, 123, 310,\n",
    "    372, 212, 1, 65, 332, 225, 156, 228, 17, 172,\n",
    "    283, 167, 124, 62, 80, 380, 144, 162, 234, 320,\n",
    "    216, 371, 388, 147, 338, 218, 238, 12, 20, 67,\n",
    "    370, 150, 343, 210, 159, 319, 340, 247, 183, 43,\n",
    "    363, 240, 289, 385, 127, 314, 168, 295, 24, 335,\n",
    "    369, 220, 116, 236, 328, 339, 133, 398, 399, 357,\n",
    "    100, 4, 322, 315, 360, 163, 23, 356, 265, 266,\n",
    "    192, 396, 13, 151, 33, 16, 253, 84, 141, 171\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def main_classical_svr_scaled_demo(\n",
    "    matfile='qm7.mat',\n",
    "    subset_size=300,\n",
    "    test_size=0.2,\n",
    "    random_seed=42\n",
    "):\n",
    "#   1) Load QM7, Flatten 23x23 Coulomb Matrices => 529 features\n",
    "    data = scipy.io.loadmat(matfile)\n",
    "    C_all = data['X']             # shape (N,23,23)\n",
    "    Y_all = data['T'].ravel()     # shape (N,)\n",
    "\n",
    "    # 1A) FLAT 529-D (default)\n",
    "    X_all = np.stack([M.flatten() for M in C_all], axis=0)\n",
    "    BEST_IDS = BEST_IDS_529\n",
    "\n",
    "#   1B) EIGENVALUE 23-D MODE (uncomment to activate)\n",
    "    \n",
    "    # compute 23 eigenvalues in-place\n",
    "    eigs = []\n",
    "    for M in C_all:\n",
    "        M_sym = 0.5*(M + M.T)\n",
    "        vals  = eigh(M_sym, eigvals_only=True)  # sorted ascending\n",
    "        eigs.append(np.sort(vals)[::-1])       # descending absolute\n",
    "    X_all   = np.array(eigs)                  # shape (N,23)\n",
    "    BEST_IDS = BEST_IDS_23\n",
    "    \n",
    " \n",
    "\n",
    "    N = len(X_all)\n",
    "    print(f\"Loaded {N} molecules; feature-dim = {X_all.shape[1]}.\")\n",
    "\n",
    "    #2) SUBSAMPLE via BEST_IDS \n",
    "    if subset_size > len(BEST_IDS):\n",
    "        raise ValueError(f\"subset_size={subset_size} exceeds BEST_IDS length={len(BEST_IDS)}\")\n",
    "    idxs = BEST_IDS[:subset_size]\n",
    "    X_sub, Y_sub = X_all[idxs], Y_all[idxs]\n",
    "    print(f\"Using top {subset_size} samples from BEST_IDS.\")\n",
    "\n",
    "    #3) SCALE FEATURES & TARGET\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_sub)\n",
    "\n",
    "    Y_mean, Y_std = Y_sub.mean(), Y_sub.std()\n",
    "    Y_scaled     = (Y_sub - Y_mean) / Y_std\n",
    "\n",
    "    #) SPLIT\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, Y_scaled, test_size=test_size, random_state=random_seed\n",
    "    )\n",
    "    print(f\"Train size = {len(X_train)}, Test size = {len(X_test)}\")\n",
    "\n",
    "    #5) FIT & PREDICT\n",
    "    svr = SVR(kernel='rbf', C=1e4, gamma=1e-3, epsilon=0.01)\n",
    "    svr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_s = svr.predict(X_test)\n",
    "    y_pred   = y_pred_s * Y_std + Y_mean\n",
    "    y_true   = y_test   * Y_std + Y_mean\n",
    "\n",
    "    #6) EVALUATE \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2  = r2_score(y_true, y_pred)\n",
    "    print(\"\\nClassical SVR (RBF) results:\")\n",
    "    print(f\"  Subset size: {subset_size}\")\n",
    "    print(f\"  MAE = {mae:.3f}\")\n",
    "    print(f\"  R²  = {r2:.3f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_classical_svr_scaled_demo(\n",
    "        matfile='/Users/franogurlic/Desktop/qm7.mat',\n",
    "        subset_size=300, #works up to 300\n",
    "        test_size=0.2,\n",
    "        random_seed=42\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
